# ðŸ¤– AI Visual Assistant
![Alt text](./Screenshot%202024-09-21%20134323.png)
## Overview

The **AI Visual Assistant** is a web application that utilizes advanced machine learning models to describe images and read text from them. Users can capture images using their camera, and the assistant will provide audio descriptions or read any text present in the images.(If you want to run this project then use gitpod and use chart-gpt project under which you have created the files to run it.)

## Features

- **Image Description**: Describes the content of images using the LLaVA model.
- **Text Recognition**: Reads and outputs text found in images.
- **Text-to-Speech**: Converts text responses into audio.
- **User-Friendly Interface**: Simple and intuitive UI for easy interaction.

## Technologies Used

- **Streamlit**: An open-source app framework for Machine Learning and Data Science projects, allowing for quick and easy deployment of interactive web applications.
  
- **LLaVA**: A multimodal AI model that integrates language and vision, enabling the application to understand and describe images accurately.

- **VITS**: A state-of-the-art text-to-speech model that converts text responses into natural-sounding audio, enhancing user interaction.

- **PIL (Pillow)**: A Python Imaging Library that provides easy-to-use methods for opening, manipulating, and saving various image file formats.

- **Torch**: A deep learning framework that provides tools for building and training machine learning models, essential for handling the underlying computations of the AI models used in the application.

## Installation

1. Clone the repository:

   ```bash
   git clone https://github.com/yourusername/AI_Visual_Assistant.git
   cd AI_Visual_Assistant
   ```
### Key Points to Customize:
- **GitHub URL**: `https://github.com/abhijeetGithu/AI_Visual_Assistant.git` 
- **Requirements**: Ensure your `requirements.txt` file includes all necessary packages.
- **Additional Sections**: Feel free to add more sections as needed, like FAQs or examples of use cases.


## Usage

1. Launch the app and take a picture using your webcam or upload an image.
2. Click "Describe the image" to get a description.
3. Click "Read the label" to have the assistant read any text aloud.

## Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository.
2. Create your feature branch.
3. Commit your changes.
4. Push to the branch.
5. Open a Pull Request.


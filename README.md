# ðŸ¤– AI Visual Assistant
![Alt text](./Screenshot%202024-09-21%20134323.png)
## Overview

The **AI Visual Assistant** is a web application that utilizes advanced machine learning models to describe images and read text from them. Users can capture images using their camera, and the assistant will provide audio descriptions or read any text present in the images.

## Features

- **Image Description**: Describes the content of images using the LLaVA model.
- **Text Recognition**: Reads and outputs text found in images.
- **Text-to-Speech**: Converts text responses into audio.
- **User-Friendly Interface**: Simple and intuitive UI for easy interaction.

## Technologies Used

- **Streamlit**: An open-source app framework for Machine Learning and Data Science projects, allowing for quick and easy deployment of interactive web applications.
  
- **LLaVA**: A multimodal AI model that integrates language and vision, enabling the application to understand and describe images accurately.

- **VITS**: A state-of-the-art text-to-speech model that converts text responses into natural-sounding audio, enhancing user interaction.

- **PIL (Pillow)**: A Python Imaging Library that provides easy-to-use methods for opening, manipulating, and saving various image file formats.

- **Torch**: A deep learning framework that provides tools for building and training machine learning models, essential for handling the underlying computations of the AI models used in the application.

## Installation

1. Clone the repository:

   ```bash
   git clone https://github.com/yourusername/AI_Visual_Assistant.git
   cd AI_Visual_Assistant
   ```
### Key Points to Customize:
- **GitHub URL**: Replace `https://github.com/abhijeetGithu/AI_Visual_Assistant.git` with your actual repository link.
- **Requirements**: Ensure your `requirements.txt` file includes all necessary packages.
- **Additional Sections**: Feel free to add more sections as needed, like FAQs or examples of use cases.




